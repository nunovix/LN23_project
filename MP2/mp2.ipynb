{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.840B.300d.zip: 2.18GB [07:01, 5.16MB/s]                                \n",
      "100%|█████████▉| 2196016/2196017 [06:46<00:00, 5400.33it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import GloVe\n",
    "from torchtext.vocab import GloVe\n",
    "global_vectors = GloVe(name='840B', dim=300)\n",
    "\n",
    "#tokenizer\n",
    "import torchtext\n",
    "from torchtext.data import get_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-pocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Review   Realness Sentiment\n",
      "0     The sheraton was a wonderful hotel! When me an...   TRUTHFUL  POSITIVE\n",
      "1     We stayed at the Omni between Christmas and Ne...   TRUTHFUL  POSITIVE\n",
      "2     I was REALLY looking forward to a nice relaxin...  DECEPTIVE  NEGATIVE\n",
      "3     First let me say, I try not to be too critical...   TRUTHFUL  NEGATIVE\n",
      "4     The Ambassador East Hotel is a terrible place ...  DECEPTIVE  NEGATIVE\n",
      "...                                                 ...        ...       ...\n",
      "1395  I stayed here for 5 nights last summer. I book...   TRUTHFUL  NEGATIVE\n",
      "1396  Stayed here for 3 nights for a Bridgestone/Fir...   TRUTHFUL  POSITIVE\n",
      "1397  I am staying here now and actually am compelle...   TRUTHFUL  NEGATIVE\n",
      "1398  We stayed at this hotel with our two teenage d...   TRUTHFUL  NEGATIVE\n",
      "1399  The rooms were beautiful! The staff was friend...  DECEPTIVE  POSITIVE\n",
      "\n",
      "[1400 rows x 3 columns]\n",
      "max_words-->864\n",
      "X_emb.shape-->(1400, 864, 300)\n",
      "max_words-->864\n",
      "X_emb.shape-->(200, 864, 300)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train.txt', delimiter='\\t', header=None, names=[\"Label\", \"Review\"])\n",
    "df_test = pd.read_csv('test_just_reviews.txt', delimiter='\\t', header=None, names=[\"Review\"])\n",
    "\n",
    "#separating the labels into real/fake and positive/negative\n",
    "df['Realness'] = df['Label'].str[:-8]\n",
    "df['Sentiment'] = df['Label'].str[-8:]\n",
    "df = df.drop('Label', axis=1)\n",
    "\n",
    "# remove capitalized letters\n",
    "#df['Review'] = df['Review'].str.lower()\n",
    "#df['Review'] = tokenizer(df['Review'])\n",
    "data = df.to_numpy()\n",
    "Xt = df_test.to_numpy()[:,0]\n",
    "\n",
    "X = data[:,0]\n",
    "yr = data[:,1]\n",
    "ys = data[:,2]\n",
    "print(df)\n",
    "\n",
    "def pre_process_x(X):\n",
    "\n",
    "    #tokenizing\n",
    "    tokenizer = get_tokenizer(\"basic_english\") \n",
    "    X = [tokenizer(x) for x in X]\n",
    "\n",
    "    #getting max numer of tokens in one review\n",
    "    '''\n",
    "    max_words = 0\n",
    "    tam = []\n",
    "    for x in X:\n",
    "        tam.append(len(x))\n",
    "        if len(x) > max_words:\n",
    "            max_words = len(x)\n",
    "    '''\n",
    "    max_words = 864\n",
    "\n",
    "    print(f\"max_words-->{max_words}\")\n",
    "\n",
    "    #padding\n",
    "    X = [tokens+[\"\"] * (max_words-len(tokens))  if len(tokens)<max_words else tokens[:max_words] for tokens in X]\n",
    "\n",
    "    #embeddings\n",
    "    X_emb = []\n",
    "    for token in X:\n",
    "        # tokenize and use glove word embedding\n",
    "        X_emb.append(np.array(global_vectors.get_vecs_by_tokens(token)))\n",
    "\n",
    "    X_emb = np.array(X_emb)\n",
    "    print(f\"X_emb.shape-->{X_emb.shape}\")\n",
    "\n",
    "    return X_emb\n",
    "\n",
    "X_emb = pre_process_x(X)\n",
    "Xt_emb = pre_process_x(Xt)\n",
    "\n",
    "######### y's pre processing\n",
    "for i in range(len(ys)):\n",
    "    if ys[i] == \"POSITIVE\":\n",
    "        ys[i] = 1\n",
    "    else:\n",
    "        ys[i] = 0\n",
    "\n",
    "    if yr[i] == \"TRUTHFUL\":\n",
    "        yr[i] = 1\n",
    "    else:\n",
    "        yr[i] = 0\n",
    "\n",
    "ys = np.array(ys)\n",
    "yr = np.array(yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(X_emb)--><class 'numpy.ndarray'>\n",
      "type(Xt_emb)--><class 'numpy.ndarray'>\n",
      "type(ys)--><class 'numpy.ndarray'>\n",
      "type(yr)--><class 'numpy.ndarray'>\n",
      "\n",
      "X_emb.shape-->(1400, 864, 300)\n",
      "Xt_emb.shape-->(200, 864, 300)\n",
      "ys.shape-->(1400,)\n",
      "yr.shape-->(1400,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"type(X_emb)-->{type(X_emb)}\")\n",
    "print(f\"type(Xt_emb)-->{type(Xt_emb)}\")\n",
    "print(f\"type(ys)-->{type(ys)}\")\n",
    "print(f\"type(yr)-->{type(yr)}\\n\")\n",
    "\n",
    "print(f\"X_emb.shape-->{X_emb.shape}\")\n",
    "print(f\"Xt_emb.shape-->{Xt_emb.shape}\")\n",
    "print(f\"ys.shape-->{ys.shape}\")\n",
    "print(f\"yr.shape-->{yr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(f\"tam_min-->{np.min(tam)}\")\\nprint(f\"tam_MAX-->{np.max(tam)}\")\\nprint(f\"tam_avg-->{np.average(tam)}\")\\nprint(f\"tam_median-->{np.average(tam)}\")\\n\\n# distribuição do numero de palavras por review\\nplt.hist(tam)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(f\"tam_min-->{np.min(tam)}\")\n",
    "print(f\"tam_MAX-->{np.max(tam)}\")\n",
    "print(f\"tam_avg-->{np.average(tam)}\")\n",
    "print(f\"tam_median-->{np.average(tam)}\")\n",
    "\n",
    "# distribuição do numero de palavras por review\n",
    "plt.hist(tam)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete cache\n",
    "del(global_vectors)\n",
    "#save processed numpy arrays\n",
    "np.save(\"./processed_train/X_emb.npy\", X_emb)\n",
    "np.save(\"./processed_train/Xt_emb.npy\", Xt_emb)\n",
    "np.save(\"./processed_train/ys.npy\", ys)\n",
    "np.save(\"./processed_train/yr.npy\", yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savez_compressed('processed_train/all.npz', X_emb=X_emb, Xt_emb=Xt_emb, ys=ys, yr=yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LN23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
