{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(X_emb)--><class 'numpy.ndarray'>\n",
      "type(Xt_emb)--><class 'numpy.ndarray'>\n",
      "type(ys)--><class 'numpy.ndarray'>\n",
      "type(yr)--><class 'numpy.ndarray'>\n",
      "\n",
      "y.shape-->(1400, 2)\n",
      "type(y)--><class 'numpy.ndarray'>\n",
      "\n",
      "X_emb.shape-->(1400, 864, 300)\n",
      "Xt_emb.shape-->(200, 864, 300)\n",
      "ys.shape-->(1400,)\n",
      "yr.shape-->(1400,)\n"
     ]
    }
   ],
   "source": [
    "X_emb = np.load(\"processed_train/X_emb.npy\", allow_pickle=True)\n",
    "Xt_emb = np.load(\"processed_train/Xt_emb.npy\", allow_pickle=True)\n",
    "yr = np.load(\"processed_train/yr.npy\", allow_pickle=True)\n",
    "ys =np.load(\"processed_train/ys.npy\", allow_pickle=True)\n",
    "yr = yr.astype('float64') \n",
    "ys = ys.astype('float64') \n",
    "\n",
    "y = np.concatenate((np.transpose([yr]), np.transpose([ys])), axis=1)\n",
    "\n",
    "print(f\"type(X_emb)-->{type(X_emb)}\")\n",
    "print(f\"type(Xt_emb)-->{type(Xt_emb)}\")\n",
    "print(f\"type(ys)-->{type(ys)}\")\n",
    "print(f\"type(yr)-->{type(yr)}\\n\")\n",
    "\n",
    "print(f\"y.shape-->{y.shape}\")\n",
    "print(f\"type(y)-->{type(y)}\\n\")\n",
    "\n",
    "print(f\"X_emb.shape-->{X_emb.shape}\")\n",
    "print(f\"Xt_emb.shape-->{Xt_emb.shape}\")\n",
    "print(f\"ys.shape-->{ys.shape}\")\n",
    "print(f\"yr.shape-->{yr.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 14:09:17.388284: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 14:10:09.414510: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 128)              186880    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 24)                3096      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 50        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 190,026\n",
      "Trainable params: 190,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, LSTM, Dense, Bidirectional\n",
    "\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_emb, y, test_size=0.1, shuffle= True, random_state=42)\n",
    "\n",
    "\n",
    "# model initialization\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(64), input_shape = (X_emb.shape[1], X_emb.shape[2])))\n",
    "model.add(Dense(24, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# model summary\n",
    "#model.build(input_shape = (64, X_emb.shape[1], X_emb.shape[2]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40/40 [==============================] - 62s 2s/step - loss: 0.4535 - accuracy: 0.6865 - val_loss: 0.4800 - val_accuracy: 0.6929\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 57s 1s/step - loss: 0.3717 - accuracy: 0.7103 - val_loss: 0.4002 - val_accuracy: 0.8071\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 44s 1s/step - loss: 0.3199 - accuracy: 0.7365 - val_loss: 0.3481 - val_accuracy: 0.7786\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 58s 1s/step - loss: 0.3019 - accuracy: 0.7246 - val_loss: 0.3309 - val_accuracy: 0.8000\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 70s 2s/step - loss: 0.2432 - accuracy: 0.7492 - val_loss: 0.3510 - val_accuracy: 0.5929\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 68s 2s/step - loss: 0.2034 - accuracy: 0.7706 - val_loss: 0.3008 - val_accuracy: 0.8500\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 73s 2s/step - loss: 0.1597 - accuracy: 0.7825 - val_loss: 0.3062 - val_accuracy: 0.7214\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 74s 2s/step - loss: 0.1417 - accuracy: 0.7746 - val_loss: 0.2624 - val_accuracy: 0.7786\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 54s 1s/step - loss: 0.1487 - accuracy: 0.7556 - val_loss: 0.3309 - val_accuracy: 0.7214\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 54s 1s/step - loss: 0.1026 - accuracy: 0.7373 - val_loss: 0.2957 - val_accuracy: 0.7643\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 52s 1s/step - loss: 0.0824 - accuracy: 0.7873 - val_loss: 0.3079 - val_accuracy: 0.8214\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.0636 - accuracy: 0.7778Restoring model weights from the end of the best epoch: 8.\n",
      "40/40 [==============================] - 47s 1s/step - loss: 0.0636 - accuracy: 0.7778 - val_loss: 0.3842 - val_accuracy: 0.6643\n",
      "Epoch 12: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f79b79641c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=5, patience=4, restore_best_weights=True)\n",
    "\n",
    "cb_plateau = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.001,\n",
    "    cooldown=0,\n",
    "    min_lr=1e-4,\n",
    ")\n",
    "\n",
    "bf = model.fit(x=X_train, y=y_train, validation_data = (X_val, y_val), epochs=50, batch_size=32, callbacks=[es, cb_plateau] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 372ms/step - loss: 0.2624 - accuracy: 0.7786\n",
      "[0.2624445855617523, 0.7785714268684387]\n"
     ]
    }
   ],
   "source": [
    "# best epoch obtained\n",
    "results_test = model.evaluate(X_val, y_val)\n",
    "print(results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 684ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84        73\n",
      "           1       0.94      0.99      0.96        69\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       142\n",
      "   macro avg       0.90      0.90      0.90       142\n",
      "weighted avg       0.90      0.90      0.90       142\n",
      " samples avg       0.70      0.69      0.69       142\n",
      "\n",
      "[[[57 10]\n",
      "  [13 60]]\n",
      "\n",
      " [[67  4]\n",
      "  [ 1 68]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nunomachado/opt/anaconda3/envs/LN23/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nunomachado/opt/anaconda3/envs/LN23/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# summary of the model applied to the validation set\n",
    "y_preds = model.predict(X_val)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(y_preds)):\n",
    "    for j in range(len(y_preds[i])):\n",
    "        if y_preds[i,j] > 0.5:\n",
    "            y_preds[i,j] = 1\n",
    "        else:\n",
    "            y_preds[i,j] = 0\n",
    "\n",
    "print(metrics.classification_report(y_val, y_preds))\n",
    "\n",
    "print(metrics.multilabel_confusion_matrix(y_val, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/nunomachado/Documents/MECD/S3/LN/LN23_project/MP2/mp2_models.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nunomachado/Documents/MECD/S3/LN/LN23_project/MP2/mp2_models.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m loss \u001b[39m=\u001b[39m bf\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nunomachado/Documents/MECD/S3/LN/LN23_project/MP2/mp2_models.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m val_loss \u001b[39m=\u001b[39m bf\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nunomachado/Documents/MECD/S3/LN/LN23_project/MP2/mp2_models.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(loss) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bf' is not defined"
     ]
    }
   ],
   "source": [
    "loss = bf.history['loss']\n",
    "val_loss = bf.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label = 'Training set')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Validation set')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = bf.history['accuracy']\n",
    "val_loss = bf.history['val_accuracy']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label = 'Training set')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Validation set')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LN23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
